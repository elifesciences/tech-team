# 2017-09-30 Journal CMS full database redux

**Incident Leader: Giorgio Sironi**

## Description

The `journal-cms--prod` stack filled the database space, breaking the PHP application at random times on login and on reads from the API.

See also [previous similar incident](2018-01-13-Journal-cms-full-database.md)

## Timeline

2019-09-24 running Drupal 8.7 migration [takes much longer on prod](https://alfred.elifesciences.org/job/prod-journal-cms/368/) than on staging despite a almost identical database

2019-09-29 ~21:15 a daily Salt highstate to update the server starts to run but hangs on `drush updatedb`, probably upon writing to the database

13:34 @nlisgo runs a [production deployment](https://alfred.elifesciences.org/job/prod-journal-cms/373) but it fails to start because the previous update is still running

16:11 @giorgiosironi kills the daily update

API calls work, cron for daily updates disabled. Last 6 hours error rate minimal so no immediate problem

17:10 PHP application completely stops, doesn't report to New Relic, 502 responses to all requests generated by the nginx reverse proxy

23:20 PHP application restarted, responses and monitoring back to normal

2019-10-30 10:28 log in is reported not to work

10:32 log in problem is reproducible

10:33 database is full

10:35 starting to update staging via Infrastructure as Code to double the storage, but mistakenly double the PHP EC2 instance disk rather than the RDS space

11:32 update completes

13:56 trying to update staging database, but there is a mismatch of versions as we only specify `5.7`

`Cannot upgrade mysql from 5.7.23 to 5.7.22`

14:00 upgrade staging database again, forcing the latest available version of MySQL which causes an upgrade from `5.7.19` to `5.7.23`

14:05 staging is not failing anymore, so updating prod at the same time to try to save time

14:44 prod update fails because of the `storage-full` state

14:48 staging updated

14:52 [prod's EC2 disk](https://console.aws.amazon.com/ec2/home?region=us-east-1#Volumes:search=vol-08346f3738e8a1969;sort=desc:size), which has been set at the same as staging for consistency, appears to have doubled as requested instead. [New Relic](https://infrastructure.newrelic.com/accounts/1451451/hosts/storage?filters=%7B%22and%22%3A%5B%7B%22or%22%3A%5B%7B%22like%22%3A%7B%22apmApplicationNames%22%3A%22%7Cjournal-cms--prod%7C%22%7D%7D%5D%7D%5D%7D&timeStart=7%20days%20ago) confirms as shows the `Disk Used %` going down on the afternoon of this day rather than the next day.

15:06 expanding database size of prod through the RDS console

15:10 free space shows up in the RDS console graphs

15:11 Elsa confirms https://prod--journal-cms.elifesciences.org is accessible again

15:24 access logs are good, New Relic monitoring still doesn't report correctly due to some graph spikes that dwarfs everything else

16:07 database state goes from `Modifying` to `Backing up`

17:13 @nlisgo runs a [production deployment](https://alfred.elifesciences.org/job/prod-journal-cms/375/console) but fails on a `/covers` smoke test unrelated error. This was already failing before to the deploy to the best of our knowledge.

2019-10-02 09:29 updating prod with Infrastructure as Code

09:50 prod update completes

2019-10-03 02:43 Luke reports good metrics, CPU increased due to `psql` backup, builds green

## Contributing Factor(s)

- no monitoring on size/free space of prod databases
- fragmentation meant staging didn't fill up like prod
- strong dependency from `elife-xpub`

## Stabilization Steps

- restart PHP application (only a temporary fix)
- skipping Infrastructure as Code (CloudFormation in this case) and add space with the RDS console
- crossed our fingers

## Impact

`journal` mitigated API calls with a cache, `elife-xpub` has no mitigation. `journal-cms` was down for the eLife staff.

- 17:10 to 23:10 on Monday
- 13:20 to 15:10 today

MTTD: 37h
MTTR: 4h40m

## Corrective Actions

- investigate when/where to run `../vendor/bin/drush paragraphs-revisions-purge`
- make https://github.com/elifesciences/builder-base-formula/blob/master/elife/config/usr-local-bin-daily-system-update#L15 timeout after 1 hour, so that if it hangs an error email is sent
- monitoring on the database space; test by filling up staging
- monitoring on fragmentation (https://www.deciusac.com/linux-2/how-to-optimize-mysql-tables-and-defragment-to-recover-space/)
- investigate caching layer in `elife-xpub`
- notify product managers of necessity of status pages to be provided by Libero products
